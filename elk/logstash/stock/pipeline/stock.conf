input {
	kafka{
		id => "stock"
		key_deserializer_class => "org.apache.kafka.common.serialization.StringDeserializer"
		value_deserializer_class => "org.apache.kafka.common.serialization.StringDeserializer"
		topics => ["STOCK_ENRICH"]
		bootstrap_servers => "kafka:9092"
		client_id => "logstash-ingesta-stock"
		group_id => "logstash-ingesta"    
		consumer_threads => "4"
		codec => json {charset => "UTF-8"}
	}
}

filter {
	if ([GPSLOCATION]){
		mutate {
			add_field => {
				location=> "%{[GPSLOCATION]}"
			}
			remove_field => ["[GPSLOCATION]"]
		}
	}
	if ([STORENAME]){
		mutate {
			add_field => {
				storeName=> "%{[STORENAME]}"
			}
			remove_field => ["[STORENAME]"]
		}
	}

	mutate{
		add_field =>  {
			id => "%{[ID]}"
			storeId => "%{[STOREID]}"		
			sku => "%{[SKU]}"
			rfidLocationId => "%{[RFIDLOCATIONID]}"  
			quantity => "%{[QUANTITY]}"			
		}
		remove_field => ["[ID]", "[STOREID]", "[SKU]", "[RFIDLOCATIONID]", "[QUANTITY]"]
	}
}

output {
	elasticsearch {			
		action => "update"
		doc_as_upsert => "true"
		document_id => "%{storeId}-%{rfidLocationId}-%{sku}"
		hosts => ["http://elasticsearch:9200"]
		index =>"stock-%{+YYYY.MM}"
	}
}